// This source code was generated by TabbyXL (http://tabbydoc.github.io)
import java.io.*;
import java.util.Arrays;

import handlers.*;
import ml.TrainingDatasetGen;
import ru.icc.td.tabbyxl.crl2j.mvngen.SpreadsheetTableExtractor;
import ru.icc.td.tabbyxl.model.CTable;
import weka.classifiers.Evaluation;
import weka.classifiers.functions.MultilayerPerceptron;
import weka.core.Instances;
import weka.core.SerializationHelper;
import weka.core.Utils;
import weka.filters.Filter;
import weka.filters.unsupervised.attribute.StringToNominal;

class SpreadsheetTableExtractorApp {
    static final SpreadsheetTableExtractor extr = new SpreadsheetTableExtractor();

    static {
        extr.register(new TableConsumer1());
        extr.register(new TableConsumer2());
        extr.register(new TableConsumer3());
        extr.register(new TableConsumer4());
        extr.register(new TableConsumer5());
        extr.register(new TableConsumer6());
        extr.register(new TableConsumer7());
        extr.register(new TableConsumer8());
        extr.register(new TableConsumer9());
        extr.register(new TableConsumer10());
        extr.register(new TableConsumer11());
        extr.register(new TableConsumer12());
        extr.register(new TableConsumer13());
        extr.register(new TableConsumer14());
        extr.register(new TableConsumer15());
        extr.register(new TableConsumer16());
    }

    private static StringToNominal filter = new StringToNominal();

    public static void main(String[] args) throws Exception {

        System.out.print("Process tables...");
        File inputExcelFile = new File(args[0]);
        CTable[] tables = extr.extract(inputExcelFile);
        /*for (CTable table : tables) {
            System.out.println(table.trace());
            table.toCanonicalForm().print();
        }*/
        System.out.println("OK");

        System.out.println();

        System.out.print("Generating dataset...");
        TrainingDatasetGen datasetGen = new TrainingDatasetGen();
        datasetGen.loadTables(tables);

        String[] options = Utils.splitOptions("-R 1,10,11,12,13,14");
        filter.setOptions(options);
        filter.setInputFormat(datasetGen.getDataset());

        Instances train = Filter.useFilter(datasetGen.getTrain(), filter);
        train.setClassIndex(train.numAttributes() - 1);
        Instances test = Filter.useFilter(datasetGen.getTest(), filter);
        test.setClassIndex(test.numAttributes() - 1);
        System.out.println("OK");

        File trainFile = new File("train.arff");
        OutputStreamWriter outputStreamWriter1 = new OutputStreamWriter(new FileOutputStream(trainFile));
        outputStreamWriter1.append(train.toString());
        outputStreamWriter1.flush();
        outputStreamWriter1.close();

        File testFile = new File("test.arff");
        OutputStreamWriter outputStreamWriter2 = new OutputStreamWriter(new FileOutputStream(testFile));
        outputStreamWriter2.append(test.toString());
        outputStreamWriter2.flush();
        outputStreamWriter2.close();

        System.out.print("Trane model...");
        MultilayerPerceptron classifier = new MultilayerPerceptron();
        classifier.buildClassifier(train);
        System.out.println("OK");

        Evaluation evaluation = new Evaluation(train);
        evaluation.evaluateModel(classifier, test);

        System.out.println(evaluation.toSummaryString("\nResults\n======\n", false));

        File modelFile = new File("model.model");
        SerializationHelper.write(modelFile.getName(), classifier);

    }
}
